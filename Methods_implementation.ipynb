{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dVJdGobKyAFI"},"outputs":[],"source":["import joblib\n","import pandas as pd\n","import numpy as np\n","import cv2\n","\n","from tqdm import tqdm\n","\n","from sklearn.feature_selection import RFE\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, f1_score\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.neural_network import MLPClassifier\n","import warnings\n","\n","# Suppress UserWarning related to feature names\n","warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"X does not have valid feature names*\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ip8KYnzlZkCE"},"outputs":[],"source":["path = '/content/drive/MyDrive/Camel'\n"]},{"cell_type":"markdown","source":["[7, 11, 15, 19, 20, 17, 13, 9, 23, 18, 3, 4]"],"metadata":{"id":"UNCaTVpASj81"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oxyh7VJgZkEW"},"outputs":[],"source":["# Load the scaler and imputer from files\n","scaler_a = joblib.load(f'{path}/scaler_a.pkl')\n","imputer_a = joblib.load(f'{path}/imputer_a.pkl')\n","model_a = joblib.load(f'{path}/model_a.pkl')\n","\n","# Load the scaler and imputer from files\n","scaler_b = joblib.load(f'{path}/scaler_b.pkl')\n","imputer_b = joblib.load(f'{path}/imputer_b.pkl')\n","model_b = joblib.load(f'{path}/model_b.pkl')\n","\n","scaler_best =joblib.load(f'{path}/scaler_best.pkl')\n","imputer_best =joblib.load(f'{path}/imputer_best.pkl')\n","model1_best = joblib.load(f'{path}/model_best1.pkl')\n","model2_best = joblib.load(f'{path}/model_best2.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBc_ijdrZqgd"},"outputs":[],"source":["def extract_image_features(frame, frame2, x, y, width, height, frame_features):\n","    # frame is visible\n","    # frame2 is IR\n","    frame_copy = frame.copy()\n","    frame2_copy = frame2.copy()\n","    roi = frame_copy[y:y+height, x:x+width]\n","    roi2 = frame2_copy[y:y+height, x:x+width]\n","\n","    frame_gray = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2GRAY)\n","    frame2_gray = cv2.cvtColor(frame2_copy, cv2.COLOR_BGR2GRAY)\n","    roi_gray = frame_gray[y:y+height, x:x+width]\n","    roi2_gray = frame2_gray[y:y+height, x:x+width]\n","\n","    rois = [(roi_gray, roi),\n","            (roi2_gray, roi2)]\n","\n","    if frame_features:\n","            rois = [(frame_gray, frame_copy),\n","            (frame2_gray, frame2_copy),\n","            (roi_gray, roi),\n","            (roi2_gray, roi2)]\n","\n","    features = []\n","\n","    for x in rois:\n","        gray_roi = x[0]\n","        roi = x[1]\n","\n","        # Convert the cropped region to BGR\n","        b, g, r = cv2.split(roi)\n","\n","        mean_intensity_b = np.mean(b)\n","        mean_intensity_g = np.mean(g)\n","        mean_intensity_r = np.mean(r)\n","\n","        # Compute median intensity directly from pixel values\n","        median_intensity_b = np.median(b)\n","        median_intensity_g = np.median(g)\n","        median_intensity_r = np.median(r)\n","\n","        # Compute mode intensity directly from pixel values\n","        mode_intensity_b = np.argmax(np.bincount(b.flatten()))\n","        mode_intensity_g = np.argmax(np.bincount(g.flatten()))\n","        mode_intensity_r = np.argmax(np.bincount(r.flatten()))\n","\n","        # Compute standard deviation directly from pixel values\n","        std_deviation_b = np.std(b)\n","        std_deviation_g = np.std(g)\n","        std_deviation_r = np.std(r)\n","\n","        # Compute intensity statistics\n","        mean_intensity = np.mean(gray_roi)\n","        variance_intensity = np.var(gray_roi)\n","        skewness_intensity = np.mean((gray_roi - mean_intensity) ** 3) / np.power(variance_intensity, 1.5)\n","        kurtosis_intensity = np.mean((gray_roi - mean_intensity) ** 4) / np.power(variance_intensity, 2) - 3\n","\n","        area = width*height\n","\n","        # Include all variables in the features list\n","        features += [mean_intensity_b, mean_intensity_g, mean_intensity_r,\n","                median_intensity_b, median_intensity_g, median_intensity_r,\n","                mode_intensity_b, mode_intensity_g, mode_intensity_r,\n","                std_deviation_b, std_deviation_g, std_deviation_r,\n","                mean_intensity, variance_intensity, skewness_intensity, kurtosis_intensity, area]\n","\n","    # Return all features\n","    return features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"paBKXL-oZoOg"},"outputs":[],"source":["def eval_sample(features, scaler, imputer, model):\n","    # Apply imputation\n","    features_imputed = imputer.transform([features])\n","\n","    # Apply scaling\n","    features_scaled = scaler.transform(features_imputed)\n","\n","    # Use the model to make predictions\n","    prediction = model.predict(features_scaled)\n","\n","    return prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NHpOrhMuxjfU"},"outputs":[],"source":["def read_bbox_data_from_dataframe(dataframe):\n","    bbox_data = {}\n","    latest_frames = {}\n","    for index, row in dataframe.iterrows():\n","        frame = int(row['frame_id'])\n","        track_id = int(row['track_id'])\n","        class_id = int(row['class_id'])\n","        bbox = [int(row['absolute_gt_x']), int(row['absolute_gt_y']), int(row['absolute_gt_width']), int(row['absolute_gt_height'])]\n","        bbox_data.setdefault(frame, []).append((track_id, bbox))\n","        latest_frames[track_id] = max(frame, latest_frames.get(track_id, 0))  # Update the latest frame for the track_id\n","    return bbox_data, latest_frames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bySP3sjxyHR"},"outputs":[],"source":["def read_absolute_truth(abs_file):\n","    df = pd.read_csv(abs_file, delimiter='\\t', names= ['frame_id', 'track_id','class_id', 'absolute_gt_x', 'absolute_gt_y', 'absolute_gt_width', 'absolute_gt_height'], dtype={'frame_id': int, 'track_id': int,'class': int, 'x': float, 'y': float, 'width': float, 'height': float}, on_bad_lines='skip')\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0UmhSxo9kKZ"},"outputs":[],"source":["def is_bbox_valid(bbox, frame):\n","    image_width, image_height, _ = frame.shape\n","    x_min, y_min, width, height = bbox\n","    x_max = x_min + width\n","    y_max = y_min + height\n","    return 0 <= x_min < x_max <= image_width and 0 <= y_min < y_max <= image_height and width > 0 and height > 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-Vz4Ck6x7hq"},"outputs":[],"source":["def adjust_bounding_box(frame, roi):\n","    height, width, _ = frame.shape\n","    height -= 1\n","    width -= 1\n","    x, y, w, h = roi\n","\n","    # Adjust x coordinate if it's less than 0\n","    if x < 0:\n","        w += x  # Decrease width\n","        x = 0   # Set x to 0\n","\n","    # Adjust width if it exceeds the frame width\n","    if x + w > width:\n","        w = width - x\n","\n","    # Adjust y coordinate if it's less than 0\n","    if y < 0:\n","        h += y  # Decrease height\n","        y = 0   # Set y to 0\n","\n","    # Adjust height if it exceeds the frame height\n","    if y + h > height:\n","        h = height - y\n","\n","    # Ensure width and height are at least 2\n","    w = max(2, w)\n","    h = max(2, h)\n","\n","        # Adjust width if it exceeds the frame width\n","    if x + w > width:\n","        x = width - w\n","\n","    # Adjust height if it exceeds the frame height\n","    if y + h > height:\n","        y = height - h\n","\n","\n","    return (x, y, w, h)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLnQDdGx44VP"},"outputs":[],"source":["import numpy as np\n","\n","def ir_better(frame_rgb, frame_ir, bbox):\n","    frame_rgb = frame_rgb.copy()\n","    frame_ir = frame_ir.copy()\n","\n","    #calculate contrast\n","    # Crop the selected ROI from the RGB image\n","    roi_rgb = frame_rgb[int(bbox[1]):int(bbox[1]+bbox[3]),\n","                    int(bbox[0]):int(bbox[0]+bbox[2])]\n","\n","    roi_ir = frame_ir[int(bbox[1]):int(bbox[1]+bbox[3]),\n","                    int(bbox[0]):int(bbox[0]+bbox[2])]\n","\n","    # Convert ROI from RGB to grayscale for contrast calculation\n","    roi_gray_rgb = cv2.cvtColor(roi_rgb, cv2.COLOR_BGR2GRAY)\n","    # Convert ROI from IR to grayscale for contrast calculation\n","    roi_gray_ir = cv2.cvtColor(roi_ir, cv2.COLOR_BGR2GRAY)\n","\n","    std_deviation_roi_rgb = np.std(roi_gray_rgb)\n","    std_deviation_roi_ir = np.std(roi_gray_ir)\n","\n","    return std_deviation_roi_ir > std_deviation_roi_rgb\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHqV34ZYOzsp"},"outputs":[],"source":["def is_mostly_dark_in_region(image, bbox, threshold=100, brightness_threshold = 20):\n","    # Extract the region of interest (ROI) from the image using the bounding box\n","    x, y, w, h = bbox\n","\n","    gray_roi = image[y:y+h, x:x+w]\n","\n","    gray_roi = cv2.cvtColor(gray_roi, cv2.COLOR_BGR2GRAY)\n","\n","    # Compute the average brightness of the ROI\n","    average_brightness = cv2.mean(gray_roi)[0]\n","\n","    # Compute the difference between the highest and lowest point in the grayscale ROI\n","    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(gray_roi)\n","    difference = max_val - min_val\n","\n","    # Check if the average brightness is below the threshold\n","    if average_brightness < threshold and difference < brightness_threshold:\n","        return True\n","    else:\n","        return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XiKu9Em3Gkz"},"outputs":[],"source":["def init_tracker_6(tracker, bbox, frame, frame2, seq):\n","    ir_is_better = ir_better(frame, frame2 ,tuple(bbox))\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better}\n","\n","def update_tracker_6(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    bbox = data['last_bbox']\n","    data['ir_better'] = ir_better(frame, frame2 ,tuple(bbox))\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    return data['tracker'].update(frame)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wbw355eN-txK"},"outputs":[],"source":["def init_tracker_1_a(tracker, bbox, frame, frame2, seq):\n","    tracker.init(frame, tuple(bbox))\n","    return {'tracker': tracker, 'last_bbox': bbox}\n","\n","def update_tracker_1_a(data, frame, frame2, seq):\n","    return data['tracker'].update(frame)\n","\n","def init_tracker_1_b(tracker, bbox, frame, frame2, seq):\n","    tracker.init(frame2, tuple(bbox))\n","    return {'tracker': tracker, 'last_bbox': bbox}\n","\n","def update_tracker_1_b(data, frame, frame2, seq):\n","    return data['tracker'].update(frame2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Wvno1LIBT7I"},"outputs":[],"source":["def init_tracker_2_a(tracker, bbox, frame, frame2, seq):\n","    tracker.init(frame, tuple(bbox))\n","    return {'tracker': tracker, 'last_bbox': bbox}\n","\n","def update_tracker_2_a(data, frame, frame2, seq):\n","    data['tracker'].update(frame2)\n","    return data['tracker'].update(frame)\n","\n","def init_tracker_2_b(tracker, bbox, frame, frame2, seq):\n","    tracker.init(frame2, tuple(bbox))\n","    return {'tracker': tracker, 'last_bbox': bbox}\n","\n","def update_tracker_2_b(data, frame, frame2, seq):\n","    data['tracker'].update(frame)\n","    return data['tracker'].update(frame2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aS9j2vtQCG-u"},"outputs":[],"source":["def init_tracker_3_a(tracker, bbox, frame, frame2, seq):\n","    tracker.init(frame, tuple(bbox))\n","    return {'tracker': tracker, 'last_bbox': bbox, 'lost_count': 0}\n","\n","def update_tracker_3_a(data, frame, frame2, seq):\n","    success, bbox = data['tracker'].update(frame)\n","    if not success:\n","      data['lost_count'] +=1\n","      if data['lost_count'] > 3:\n","          success, bbox = data['tracker'].update(frame2)\n","    else:\n","        data['lost_count'] = 0\n","\n","    return success, bbox\n","\n","def init_tracker_3_b(tracker, bbox, frame, frame2, seq):\n","    tracker.init(frame2, tuple(bbox))\n","    return {'tracker': tracker, 'last_bbox': bbox, 'lost_count': 0}\n","\n","def update_tracker_3_b(data, frame, frame2, seq):\n","    success, bbox = data['tracker'].update(frame2)\n","    if not success:\n","      data['lost_count'] +=1\n","      if data['lost_count'] > 3:\n","          success, bbox = data['tracker'].update(frame)\n","    else:\n","        data['lost_count'] = 0\n","\n","    return success, bbox"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aa8mJWIlDm5D"},"outputs":[],"source":["def init_tracker_4(tracker, bbox, frame, frame2, seq):\n","    tracker.init(frame2, tuple(bbox))\n","    return {'tracker': tracker, 'last_bbox': bbox, 'frame_counter': 0}\n","\n","def update_tracker_4(data, frame, frame2, seq):\n","    if data['frame_counter'] % 2 == 0:\n","        frame, frame2 = frame2.copy(), frame.copy()\n","\n","    return data['tracker'].update(frame)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rmRIPYB4I2jl"},"outputs":[],"source":["def init_tracker_5(tracker, bbox, frame, frame2, seq):\n","    ir_is_better = is_mostly_dark_in_region(frame, bbox)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better}\n","\n","def update_tracker_5(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    bbox = data['last_bbox']\n","    data['ir_better'] = is_mostly_dark_in_region(frame, bbox)\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    return data['tracker'].update(frame)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Gy77E9VY-9u"},"outputs":[],"source":["def init_tracker_7_a(tracker, bbox, frame, frame2, seq):\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = True)\n","    ir_is_better = eval_sample(features, scaler_a, imputer_a, model_a)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better, 'lost_count': 0}\n","\n","def update_tracker_7_a(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    success, bbox = data['tracker'].update(frame)\n","\n","    if not success:\n","        data['lost_count'] +=1\n","        if data['lost_count'] > 3:\n","            success, bbox = data['tracker'].update(frame2)\n","    else:\n","        data['lost_count'] = 0\n","\n","    return success, bbox\n","\n","def init_tracker_7_b(tracker, bbox, frame, frame2, seq):\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    ir_is_better = eval_sample(features, scaler_b, imputer_b, model_b)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better, 'lost_count': 0}\n","\n","def update_tracker_7_b(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    success, bbox = data['tracker'].update(frame)\n","\n","    if not success:\n","        data['lost_count'] +=1\n","        if data['lost_count'] > 3:\n","            success, bbox = data['tracker'].update(frame2)\n","    else:\n","        data['lost_count'] = 0\n","\n","    return success, bbox\n","\n","def init_tracker_7_best(tracker, bbox, frame, frame2, seq):\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    if seq in [7, 11, 15, 19, 20, 17, 13, 9, 23, 18, 3, 4]:\n","      model = model2_best\n","    else:\n","      model = model1_best\n","    ir_is_better = eval_sample(features, scaler_best, imputer_best, model)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better, 'lost_count': 0}\n","\n","def update_tracker_7_best(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    success, bbox = data['tracker'].update(frame)\n","\n","    if not success:\n","        data['lost_count'] +=1\n","        if data['lost_count'] > 3:\n","            success, bbox = data['tracker'].update(frame2)\n","    else:\n","        data['lost_count'] = 0\n","\n","    return success, bbox"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59G4qKjGaVf1"},"outputs":[],"source":["def init_tracker_8_a(tracker, bbox, frame, frame2, seq):\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = True)\n","    ir_is_better = eval_sample(features, scaler_a, imputer_a, model_a)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better}\n","\n","def update_tracker_8_a(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    bbox = data['last_bbox']\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = True)\n","    data['ir_better'] = eval_sample(features, scaler_a, imputer_a, model_a)\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    return data['tracker'].update(frame)\n","\n","def init_tracker_8_b(tracker, bbox, frame, frame2, seq):\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    ir_is_better = eval_sample(features, scaler_b, imputer_b, model_b)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better}\n","\n","def update_tracker_8_b(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    bbox = data['last_bbox']\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    data['ir_better'] = eval_sample(features, scaler_b, imputer_b, model_b)\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    return data['tracker'].update(frame)\n","\n","def init_tracker_8_best(tracker, bbox, frame, frame2, seq):\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    if seq in [7, 11, 15, 19, 20, 17, 13, 9, 23, 18, 3, 4]:\n","      model = model2_best\n","    else:\n","      model = model1_best\n","    ir_is_better = eval_sample(features, scaler_best, imputer_best, model)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better}\n","\n","def update_tracker_8_best(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    bbox = data['last_bbox']\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    if seq in [7, 11, 15, 19, 20, 17, 13, 9, 23, 18, 3, 4]:\n","      model = model2_best\n","    else:\n","      model = model1_best\n","    data['ir_better'] = eval_sample(features, scaler_best, imputer_best, model)\n","\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    return data['tracker'].update(frame)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nMix20njlGY"},"outputs":[],"source":["def init_tracker_9_a(tracker, bbox, frame, frame2, seq):\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = True)\n","    ir_is_better = eval_sample(features, scaler_a, imputer_a, model_a)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better, 'switch_count': 0}\n","\n","def update_tracker_9_a(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    bbox = data['last_bbox']\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = True)\n","    ir_better = eval_sample(features, scaler_a, imputer_a, model_a)\n","    if data['ir_better'] != ir_better:\n","        data['switch_count'] += 1\n","        if data['switch_count'] > 3:\n","            data['ir_better'] = ir_better\n","            data['switch_count'] = 0\n","    else:\n","        data['switch_count'] = 0\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    success, bbox = data['tracker'].update(frame)\n","\n","    return data['tracker'].update(frame)\n","\n","def init_tracker_9_b(tracker, bbox, frame, frame2, seq):\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    ir_is_better = eval_sample(features, scaler_b, imputer_b, model_b)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better, 'switch_count': 0}\n","\n","def update_tracker_9_b(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    bbox = data['last_bbox']\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    ir_better = eval_sample(features, scaler_b, imputer_b, model_b)\n","    if data['ir_better'] != ir_better:\n","        data['switch_count'] += 1\n","        if data['switch_count'] > 3:\n","            data['ir_better'] = ir_better\n","            data['switch_count'] = 0\n","    else:\n","        data['switch_count'] = 0\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    success, bbox = data['tracker'].update(frame)\n","\n","    return data['tracker'].update(frame)\n","\n","def init_tracker_9_best(tracker, bbox, frame, frame2, seq):\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    if seq in [7, 11, 15, 19, 20, 17, 13, 9, 23, 18, 3, 4]:\n","      model = model2_best\n","    else:\n","      model = model1_best\n","    ir_is_better = eval_sample(features, scaler_best, imputer_best, model)\n","\n","    if ir_is_better:\n","        tracker.init(frame2, tuple(bbox))\n","    else:\n","        tracker.init(frame, tuple(bbox))\n","\n","    return {'tracker': tracker, 'last_bbox': bbox,'ir_better': ir_is_better, 'switch_count': 0}\n","\n","def update_tracker_9_best(data, frame, frame2, seq):\n","    frame = frame.copy()\n","    frame2 = frame2.copy()\n","\n","    bbox = data['last_bbox']\n","    x, y, w, h = bbox\n","    features = extract_image_features(frame, frame2, x, y, w, h, frame_features = False)\n","    if seq in [7, 11, 15, 19, 20, 17, 13, 9, 23, 18, 3, 4]:\n","      model = model2_best\n","    else:\n","      model = model1_best\n","    ir_is_better = eval_sample(features, scaler_best, imputer_best, model)\n","\n","    if data['ir_better'] != ir_better:\n","        data['switch_count'] += 1\n","        if data['switch_count'] > 3:\n","            data['ir_better'] = ir_better\n","            data['switch_count'] = 0\n","    else:\n","        data['switch_count'] = 0\n","\n","    if data['ir_better']:\n","        frame, frame2 = frame2, frame\n","\n","    success, bbox = data['tracker'].update(frame)\n","\n","    return data['tracker'].update(frame)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ey9WKj7UVQj2"},"outputs":[],"source":["# Map the function numbers and versions to the actual functions\n","init_tracker_functions = {\n","    (1, 'VIS'): init_tracker_1_a,\n","    (1, 'IR'): init_tracker_1_b,\n","    (2, 'VIS'): init_tracker_2_a,\n","    (2, 'IR'): init_tracker_2_b,\n","    (3, 'VIS'): init_tracker_3_a,\n","    (3, 'IR'): init_tracker_3_b,\n","    (4, None): init_tracker_4,\n","    (5, None): init_tracker_5,\n","    (6, None): init_tracker_6,\n","    (7, 'A'): init_tracker_7_a,\n","    (7, 'B'): init_tracker_7_b,\n","    (7, 'BEST'): init_tracker_7_best,\n","    (8, 'A'): init_tracker_8_a,\n","    (8, 'B'): init_tracker_8_b,\n","    (8, 'BEST'): init_tracker_8_best,\n","    (9, 'A'): init_tracker_9_a,\n","    (9, 'B'): init_tracker_9_b,\n","    (9, 'BEST'): init_tracker_9_best,\n","}\n","\n","update_tracker_functions = {\n","    (1, 'VIS'): update_tracker_1_a,\n","    (1, 'IR'): update_tracker_1_b,\n","    (2, 'VIS'): update_tracker_2_a,\n","    (2, 'IR'): update_tracker_2_b,\n","    (3, 'VIS'): update_tracker_3_a,\n","    (3, 'IR'): update_tracker_3_b,\n","    (4, None): update_tracker_4,\n","    (5, None): update_tracker_5,\n","    (6, None): update_tracker_6,\n","    (7, 'A'): update_tracker_7_a,\n","    (7, 'B'): update_tracker_7_b,\n","    (7, 'BEST'): update_tracker_7_best,\n","    (8, 'A'): update_tracker_8_a,\n","    (8, 'B'): update_tracker_8_b,\n","    (8, 'BEST'): update_tracker_8_best,\n","    (9, 'A'): update_tracker_9_a,\n","    (9, 'B'): update_tracker_9_b,\n","    (9, 'BEST'): update_tracker_9_best,\n","}\n","\n","# Create a list of keys from init_tracker_functions\n","init_tracker_keys = list(init_tracker_functions.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1717760012630,"user":{"displayName":"tomáš dujsík","userId":"16729605582990929868"},"user_tz":-120},"id":"OzfjLEogFV-e","outputId":"849ab1a6-bde9-4119-cd67-b94f22aedb60"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(1, 'VIS'),\n"," (1, 'IR'),\n"," (2, 'VIS'),\n"," (2, 'IR'),\n"," (3, 'VIS'),\n"," (3, 'IR'),\n"," (4, None),\n"," (5, None),\n"," (6, None),\n"," (7, 'A'),\n"," (7, 'B'),\n"," (7, 'BEST'),\n"," (8, 'A'),\n"," (8, 'B'),\n"," (8, 'BEST'),\n"," (9, 'A'),\n"," (9, 'B'),\n"," (9, 'BEST')]"]},"metadata":{},"execution_count":26}],"source":["init_tracker_keys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u1xhwaGNyJpf"},"outputs":[],"source":["def annotate(vid_in_vis, vid_in_ir, annotation, annotation_file_out, tracker_number, seq, tracker_version=None):\n","    # Get the appropriate init and update functions based on tracker_number and tracker_version\n","    init_tracker = init_tracker_functions[(tracker_number, tracker_version)]\n","    update_tracker = update_tracker_functions[(tracker_number, tracker_version)]\n","\n","    trackers = {}\n","    # Process frames and initialize trackers\n","    cap = cv2.VideoCapture(vid_in_vis)\n","    cap2 = cv2.VideoCapture(vid_in_ir)\n","\n","    annotation_df = read_absolute_truth(annotation)\n","    bbox_data, latest_frames = read_bbox_data_from_dataframe(annotation_df)\n","\n","    with open(annotation_file_out, 'w') as file:\n","        while cap.isOpened() and cap2.isOpened():\n","            ret, frame = cap.read()\n","            ret2, frame2 = cap2.read()\n","            if not ret or not ret2:\n","                break\n","\n","            frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n","\n","            # Initialize trackers at the earliest frame where track_id appears\n","            if frame_number in bbox_data:\n","                for track_id, bbox in bbox_data[frame_number]:\n","                    if track_id not in trackers:\n","                        tracker = cv2.TrackerCSRT_create()\n","                        bbox = adjust_bounding_box(frame2, bbox)\n","\n","                        trackers[track_id] = init_tracker(tracker, bbox, frame, frame2, seq)\n","\n","            # Update trackers and draw bounding boxes\n","            for track_id, data in trackers.items():\n","\n","                success, bbox = update_tracker(data, frame, frame2, seq)\n","\n","                if success and is_bbox_valid(bbox, frame):\n","                    x, y, w, h = bbox\n","                    file.write(f\"{frame_number} {track_id} {-1} {x} {y} {w} {h}\\n\")\n","                    data['last_bbox'] = bbox\n","\n","\n","            for track_id, value in latest_frames.items():\n","                if value == frame_number:\n","                    # Delete the tracker associated with the current track ID\n","                    del trackers[track_id]\n","\n","            # Press 'q' to quit\n","            if cv2.waitKey(25) & 0xFF == ord('q'):\n","                break\n","\n","    # Release resources\n","    cap.release()\n","    cap2.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ONifGASAmj0"},"outputs":[],"source":["#7;6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5iLaJDlPZXoK","outputId":"ec4395df-ab74-495b-9e90-52bff15e15a4","executionInfo":{"status":"ok","timestamp":1717757960282,"user_tz":-120,"elapsed":2819902,"user":{"displayName":"tomáš dujsík","userId":"16729605582990929868"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/4 [00:00<?, ?it/s]\n","  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n"," 67%|██████▋   | 12/18 [07:50<03:55, 39.23s/it]\u001b[A\n"," 83%|████████▎ | 15/18 [17:04<03:52, 77.44s/it]\u001b[A\n","100%|██████████| 18/18 [33:31<00:00, 111.74s/it]\n"," 25%|██▌       | 1/4 [33:31<1:40:34, 2011.35s/it]\n","  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n"," 67%|██████▋   | 12/18 [16:56<08:28, 84.72s/it]\u001b[A\n"," 83%|████████▎ | 15/18 [32:55<07:19, 146.50s/it]\u001b[A\n","100%|██████████| 18/18 [1:07:19<00:00, 224.44s/it]\n"," 50%|█████     | 2/4 [1:40:51<1:46:49, 3204.63s/it]\n","  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n"," 67%|██████▋   | 12/18 [12:58<06:29, 64.89s/it]\u001b[A\n"," 83%|████████▎ | 15/18 [28:05<06:22, 127.39s/it]\u001b[A\n","100%|██████████| 18/18 [55:09<00:00, 183.87s/it]\n"," 75%|███████▌  | 3/4 [2:36:00<54:12, 3252.57s/it]  \n","  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n"," 67%|██████▋   | 12/18 [01:48<00:54,  9.08s/it]\u001b[A\n"," 83%|████████▎ | 15/18 [03:20<00:44, 14.74s/it]\u001b[A\n","100%|██████████| 18/18 [05:51<00:00, 19.54s/it]\n","100%|██████████| 4/4 [2:41:52<00:00, 2428.16s/it]\n"]}],"source":["for i in tqdm(range(1, 31)):\n","    if i in [22,24,16,14,12]:\n","        continue\n","    for (tracker_number, tracker_version) in tqdm(init_tracker_keys):\n","        annotate(f'{path}/seq-{i}/Visual-seq{i}.mp4',\n","                f'{path}/seq-{i}/IR-seq{i}.mp4',\n","                f'{path}/seq-{i}/Seq{i}-Abs.txt',\n","                f'{path}/results/seq-{i}/Seq{i}-{tracker_number}-{tracker_version}-Out.txt',\n","                tracker_number,\n","                i,\n","                tracker_version,\n","                )"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1nroJG0_iFAkm-y8uYfzo7kJphmopd_al","authorship_tag":"ABX9TyOZa357d6NQ3X66kw9tjDmQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}